{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_4EsiO_yMNCl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "import itertools\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create coocurence matrix"
      ],
      "metadata": {
        "id": "xrWBNCmRPZSY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step1**: preprocessing "
      ],
      "metadata": {
        "id": "k0k3mVdQSI1s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we use a single sentence as our corpus to illustrate the computation of word co-occurence. The creation of a vocabulary and a set of index is necessary for the following calculation."
      ],
      "metadata": {
        "id": "691KVXpTBymV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create corpus\n",
        "corpus_test = [[\"your\", \"model\", \"is\", \"only\", \"as\", \"good\", \"as\", \"your\", \"data\"]]\n",
        "\n",
        "#build vocabulary\n",
        "vocab = set()\n",
        "for s in corpus_test:\n",
        "  vocab = vocab.union(set(s))\n",
        "\n",
        "#get all words\n",
        "words = [item for sublist in corpus_test for item in sublist]\n",
        "\n",
        "#count the occurence of each word\n",
        "counter = Counter(words)\n",
        "\n",
        "#word occurence in the corpus\n",
        "print(Counter(words))"
      ],
      "metadata": {
        "id": "Ml1vHkJEPqkZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2c613d6-354d-43d2-fa4e-c30c8bf807eb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'your': 2, 'as': 2, 'model': 1, 'is': 1, 'only': 1, 'good': 1, 'data': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create index for the vocabulary\n",
        "vocab_index = {word: i for i, word in enumerate(vocab)}\n",
        "\n",
        "print(vocab_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlSi5PTgTd2K",
        "outputId": "8554ab7c-991a-41fb-c651-eb3f4ebccde3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'as': 0, 'model': 1, 'good': 2, 'is': 3, 'your': 4, 'data': 5, 'only': 6}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step2**: co-ocurrence matrix of all words"
      ],
      "metadata": {
        "id": "H0hJg_PkFjyA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To count the co-occurence of the words, we need to select a center word and a context word in each iteration, thus, a combination of two loops is needed. "
      ],
      "metadata": {
        "id": "EDjPdKfBBND-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "co_occurrence_matrix = np.zeros((len(vocab), len(vocab)))\n",
        "\n",
        "for s in corpus_test:\n",
        "  for i in range(len(s)):\n",
        "    word_i = s[i]\n",
        "    pos_i = vocab_index[word_i]\n",
        "    for j in range(max(i-5,0), min(i+6,len(s))):\n",
        "      if j!= i:\n",
        "        word_j = s[j]\n",
        "        pos_j = vocab_index[word_j]\n",
        "        co_occurrence_matrix[pos_i][pos_j] = co_occurrence_matrix[pos_i][pos_j] + 0.5/abs(i-j)\n",
        "        co_occurrence_matrix[pos_j][pos_i] = co_occurrence_matrix[pos_i][pos_j]\n",
        "\n",
        "co_occurrence_matrix = np.matrix(co_occurrence_matrix)\n",
        "co_occurrence_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6P26wh__Wed5",
        "outputId": "a7eebe47-8062-46b7-8e25-d9d4d93cb3b2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0.5       , 0.53333333, 2.        , 0.75      , 1.58333333,\n",
              "         0.75      , 1.33333333],\n",
              "        [0.53333333, 0.        , 0.25      , 1.        , 1.        ,\n",
              "         0.        , 0.5       ],\n",
              "        [2.        , 0.25      , 0.        , 0.33333333, 0.7       ,\n",
              "         0.33333333, 0.5       ],\n",
              "        [0.75      , 1.        , 0.33333333, 0.        , 0.7       ,\n",
              "         0.        , 1.        ],\n",
              "        [1.58333333, 1.        , 0.7       , 0.7       , 0.        ,\n",
              "         1.        , 0.58333333],\n",
              "        [0.75      , 0.        , 0.33333333, 0.        , 1.        ,\n",
              "         0.        , 0.2       ],\n",
              "        [1.33333333, 0.5       , 0.5       , 1.        , 0.58333333,\n",
              "         0.2       , 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}